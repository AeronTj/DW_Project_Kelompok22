#!/bin/bash
# PT XYZ Data Warehouse - Comprehensive Startup Script
# For Technical and Non-Technical Users

# Colors for better visibility
GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Configuration
PROJECT_NAME="PT XYZ Data Warehouse"
COMPOSE_FILE="docker-compose.yml"
ENV_FILE=".env"

echo -e "${BLUE}üè≠ ${PROJECT_NAME} - Comprehensive Startup${NC}"
echo -e "${BLUE}==============================================${NC}"
echo ""

# Check if we're in the right directory
if [[ ! -f "${COMPOSE_FILE}" ]]; then
    echo -e "${RED}‚ùå Error: docker-compose.yml not found${NC}"
    echo -e "${YELLOW}üí° Please run this script from the project root directory${NC}"
    echo -e "${YELLOW}   Expected: /home/egistr/Documents/kuliah/semester6/dw/DW_Project_Kelompok22${NC}"
    exit 1
fi

# Check if Docker is running
echo -e "${CYAN}üîç Checking Docker status...${NC}"
if ! docker info >/dev/null 2>&1; then
    echo -e "${RED}‚ùå Docker is not running. Please start Docker first.${NC}"
    exit 1
fi

# Create .env file if it doesn't exist
if [[ ! -f "${ENV_FILE}" ]]; then
    echo -e "${YELLOW}üìù Creating environment configuration...${NC}"
    cat > "${ENV_FILE}" << EOF
# PT XYZ Data Warehouse Environment Configuration
# Generated: $(date)

# SQL Server Configuration
MSSQL_SA_PASSWORD=PTXYZSecure123!
MSSQL_PID=Express

# PostgreSQL Configuration (for Airflow)
POSTGRES_USER=airflow
POSTGRES_PASSWORD=airflow
POSTGRES_DB=airflow

# Redis Configuration
REDIS_PASSWORD=ptxyz123

# Airflow Configuration
AIRFLOW_UID=50000
AIRFLOW__CORE__EXECUTOR=CeleryExecutor
AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
AIRFLOW__CORE__LOAD_EXAMPLES=false
AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth
_AIRFLOW_WWW_USER_USERNAME=admin
_AIRFLOW_WWW_USER_PASSWORD=admin

# Superset Configuration
SUPERSET_SECRET_KEY=ptxyz_superset_secret_key_2025
SUPERSET_USERNAME=admin
SUPERSET_PASSWORD=admin
SUPERSET_EMAIL=admin@ptxyz.com

# Jupyter Configuration
JUPYTER_ENABLE_LAB=yes
JUPYTER_TOKEN=ptxyz123

# Grafana Configuration
GF_SECURITY_ADMIN_PASSWORD=admin
GF_USERS_ALLOW_SIGN_UP=false

# Metabase Configuration
MB_DB_TYPE=postgres
MB_DB_DBNAME=metabase
MB_DB_PORT=5432
MB_DB_USER=metabase
MB_DB_PASS=metabase
MB_DB_HOST=postgres_metabase
EOF
    echo -e "${GREEN}‚úÖ Environment file created${NC}"
fi

# Create necessary directories
echo -e "${CYAN}üìÅ Creating necessary directories...${NC}"
mkdir -p logs/airflow/{dags,logs,plugins} data/{raw,processed,staging} notebooks grafana/{dashboards,datasources} init-scripts

# Set proper permissions for Airflow
echo -e "${CYAN}üîê Setting up permissions...${NC}"
sudo chown -R 50000:0 logs/airflow/logs
sudo chown -R 50000:0 dags
sudo chown -R 50000:0 plugins 2>/dev/null || true

echo -e "${YELLOW}üîÑ Starting ${PROJECT_NAME}...${NC}"
echo "This process will take 3-5 minutes depending on your system..."
echo ""

# Stop any existing containers
echo -e "${BLUE}üõë Stopping any existing containers...${NC}"
docker compose down --remove-orphans 2>/dev/null || true

# Pull latest images
echo -e "${BLUE}üì• Pulling latest Docker images...${NC}"
docker compose pull

# Start core infrastructure first
echo -e "${BLUE}üöÄ Starting core infrastructure...${NC}"
docker compose up -d sqlserver postgres redis

# Wait for databases to be ready
echo -e "${YELLOW}‚è≥ Waiting for databases to initialize...${NC}"
sleep 30

# Check SQL Server health
echo -e "${CYAN}üîç Checking SQL Server health...${NC}"
max_attempts=12
attempt=1
while [ $attempt -le $max_attempts ]; do
    if docker compose exec -T sqlserver /opt/mssql-tools18/bin/sqlcmd -S localhost -U sa -P 'PTXYZSecure123!' -Q "SELECT 1" -C -N >/dev/null 2>&1; then
        echo -e "${GREEN}‚úÖ SQL Server is ready${NC}"
        break
    fi
    echo "Attempt $attempt/$max_attempts - SQL Server not ready yet..."
    sleep 10
    ((attempt++))
done

if [ $attempt -gt $max_attempts ]; then
    echo -e "${RED}‚ùå SQL Server failed to start within expected time${NC}"
    exit 1
fi

# Initialize database schema
echo -e "${BLUE}üèóÔ∏è  Initializing database schema...${NC}"
docker compose up -d db_init
sleep 20

# Start Airflow services
echo -e "${BLUE}‚úàÔ∏è  Starting Airflow services...${NC}"
docker compose up -d airflow-webserver airflow-scheduler airflow-worker

# Start visualization services
echo -e "${BLUE}üìä Starting visualization services...${NC}"
docker compose up -d superset grafana jupyter metabase postgres_metabase

# Final health check
echo -e "${YELLOW}‚è≥ Performing final health checks...${NC}"
sleep 45

# Check service status
echo -e "${CYAN}üîç Checking service status...${NC}"
services=("sqlserver" "airflow-webserver" "superset" "grafana" "jupyter")
for service in "${services[@]}"; do
    if docker compose ps | grep -q "${service}.*Up"; then
        echo -e "  ‚úÖ ${service} is running"
    else
        echo -e "  ‚ö†Ô∏è  ${service} may have issues"
    fi
done

echo ""
echo -e "${GREEN}üéâ ${PROJECT_NAME} is Ready!${NC}"
echo -e "${GREEN}========================================${NC}"
echo ""

echo -e "${BLUE}üìä Access Your Services:${NC}"
echo -e "  ‚Ä¢ ${CYAN}Airflow (ETL Pipeline):${NC}     http://localhost:8080"
echo -e "    Username: admin | Password: admin"
echo ""
echo -e "  ‚Ä¢ ${CYAN}Grafana (Operations):${NC}       http://localhost:3000"
echo -e "    Username: admin | Password: admin"
echo ""
echo -e "  ‚Ä¢ ${CYAN}Superset (Analytics):${NC}       http://localhost:8088"
echo -e "    Username: admin | Password: admin"
echo ""
echo -e "  ‚Ä¢ ${CYAN}Metabase (BI Reports):${NC}      http://localhost:3001"
echo -e "    Setup required on first visit"
echo ""
echo -e "  ‚Ä¢ ${CYAN}Jupyter (Data Science):${NC}     http://localhost:8888"
echo -e "    Token: ptxyz123"
echo ""

echo -e "${PURPLE}üéØ Quick Start Guide:${NC}"
echo -e "  1. Open Airflow: http://localhost:8080"
echo -e "  2. Enable and run the DAG: 'ptxyz_comprehensive_etl'"
echo -e "  3. Monitor progress in Airflow dashboard"
echo -e "  4. Access dashboards once data is loaded"
echo ""

echo -e "${YELLOW}üîß Management Commands:${NC}"
echo -e "  ‚Ä¢ Status Check:    ./bin/status.sh"
echo -e "  ‚Ä¢ Stop Services:   ./bin/stop.sh"
echo -e "  ‚Ä¢ View Logs:       docker compose logs -f [service_name]"
echo -e "  ‚Ä¢ Restart:         docker compose restart [service_name]"
echo ""

echo -e "${BLUE}üìö Documentation:${NC}"
echo -e "  ‚Ä¢ User Guide:      docs/USER_GUIDE.md"
echo -e "  ‚Ä¢ Architecture:    docs/architecture/ARCHITECTURE.md"
echo -e "  ‚Ä¢ Quick Setup:     docs/deployment/QUICKSTART.md"
echo ""

echo -e "${GREEN}üöÄ System Status: OPERATIONAL${NC}"
echo -e "${GREEN}Happy Data Mining! ‚õèÔ∏èüìà${NC}"

# Show resource usage
echo ""
echo -e "${CYAN}üíª Resource Usage:${NC}"
docker stats --no-stream --format "table {{.Name}}\t{{.CPUPerc}}\t{{.MemUsage}}" | head -10
